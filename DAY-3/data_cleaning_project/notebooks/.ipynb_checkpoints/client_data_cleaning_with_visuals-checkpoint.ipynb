{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45727c09",
   "metadata": {},
   "source": [
    "# Client Data Cleaning â€” Template with Visualizations\n",
    "This notebook is a client-ready, reproducible pipeline that:\n",
    "- Loads raw data\n",
    "- Profiles & documents issues\n",
    "- Cleans data (types, missing, duplicates, outliers)\n",
    "- Visualizes key checks (missingness, distributions, outliers)\n",
    "- Exports cleaned data\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dde04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = 'data/messy_customers.csv'\n",
    "df_raw = pd.read_csv(RAW_PATH)\n",
    "df = df_raw.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc5432",
   "metadata": {},
   "source": [
    "## 1. Initial profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rows,Cols:', df.shape)\n",
    "print('\\nData types:')\n",
    "print(df.dtypes)\n",
    "\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada44fd7",
   "metadata": {},
   "source": [
    "## 2. Visualize missingness and distributions\n",
    "We use matplotlib to show missing counts and distributions. (No seaborn.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness bar chart\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,4))\n",
    "missing.plot.bar()\n",
    "plt.title('Missing values per column')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of amount_spent (raw) - convert to numeric first (coerce errors)\n",
    "df['amount_spent_raw'] = df['amount_spent']\n",
    "df['amount_spent'] = df['amount_spent'].replace('[\\$,]', '', regex=True)\n",
    "df['amount_spent'] = pd.to_numeric(df['amount_spent'], errors='coerce')\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df['amount_spent'].dropna(), bins=10)\n",
    "plt.title('Distribution of amount_spent (raw)')\n",
    "plt.xlabel('amount_spent')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7254a0",
   "metadata": {},
   "source": [
    "## 3. Cleaning steps (types, text, dates, missing, duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cffbac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim and normalize text columns\n",
    "text_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Normalize country to uppercase and common variants\n",
    "if 'country' in df.columns:\n",
    "    df['country'] = df['country'].str.upper().replace({\n",
    "        'UNITED STATES':'US','U.S.':'US','U.S.A.':'US','USA':'US','BD':'BD','BD.':'BD'\n",
    "    })\n",
    "\n",
    "# Parse dates\n",
    "if 'signup_date' in df.columns:\n",
    "    df['signup_date'] = pd.to_datetime(df['signup_date'], errors='coerce')\n",
    "\n",
    "# Fix amounts already done above - keep numeric\n",
    "# Age: coerce to numeric and handle invalid ages\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "df.loc[(df['age'] < 0) | (df['age'] > 120), 'age'] = np.nan\n",
    "\n",
    "# Email: simple validity flag (contains @ and .)\n",
    "df['email_valid'] = df['email'].str.contains('@') & df['email'].str.contains('\\.')\n",
    "\n",
    "# Create flags for missingness before imputation\n",
    "for col in ['email','age','amount_spent','signup_date']:\n",
    "    if col in df.columns:\n",
    "        df[col + '_was_missing'] = df[col].isna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee6a1b",
   "metadata": {},
   "source": [
    "## 4. Visual checks after initial cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ed2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness after parsing\n",
    "missing_after = df.isna().sum().sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,4))\n",
    "missing_after.plot.bar()\n",
    "plt.title('Missing values per column (after parsing)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for amount_spent to detect outliers\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.boxplot(df['amount_spent'].dropna(), vert=False)\n",
    "plt.title('Boxplot of amount_spent (after parsing)')\n",
    "plt.xlabel('amount_spent')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427567a",
   "metadata": {},
   "source": [
    "## 5. Handling missing values\n",
    "Numeric imputation with median; categorical imputation with 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90efc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric median imputation for amount_spent, age\n",
    "for col in ['amount_spent','age']:\n",
    "    if col in df.columns:\n",
    "        median = df[col].median()\n",
    "        df[col] = df[col].fillna(median)\n",
    "\n",
    "# Categorical imputation\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].replace({'nan': np.nan, 'None': np.nan})\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# Recompute email_valid\n",
    "df['email_valid'] = df['email'].str.contains('@') & df['email'].str.contains('\\.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd42a9",
   "metadata": {},
   "source": [
    "## 6. Duplicates handling\n",
    "We will deduplicate by customer_id keeping the most recent signup_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f839d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep most recent per customer_id (if id missing, keep rows as is)\n",
    "if 'customer_id' in df.columns and 'signup_date' in df.columns:\n",
    "    df = df.sort_values('signup_date').drop_duplicates(subset='customer_id', keep='last')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d362dd",
   "metadata": {},
   "source": [
    "## 7. Final checks & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28522f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final shape:', df.shape)\n",
    "print('\\nMissing values:')\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Save cleaned dataset\n",
    "OUTPUT = 'data/cleaned_customers.csv'\n",
    "df.to_csv(OUTPUT, index=False)\n",
    "print('\\nSaved cleaned data to', OUTPUT)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
